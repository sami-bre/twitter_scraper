{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraper using Selenium\n",
    "\n",
    "Scraper for Twitter Tweets using selenium. It can scrape tweets from:\n",
    "- Home/New Feeds\n",
    "- User Profile Tweets\n",
    "- Query or Search Tweets\n",
    "- Hashtags Tweets\n",
    "- Advanced Search Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140.68s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages/OpenSSL/SSL.py:15: CryptographyDeprecationWarning: Python 3.7 is no longer supported by the Python core team and support for it is deprecated in cryptography. A future release of cryptography will remove support for Python 3.7.\n",
      "  from cryptography import x509\n",
      "Requirement already satisfied: fake_headers in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dotenv in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (0.21.1)\n",
      "Requirement already satisfied: selenium-wire in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (5.1.0)\n",
      "Requirement already satisfied: webdriver_manager in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (4.0.2)\n",
      "Requirement already satisfied: dotenv in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (0.9.9)\n",
      "Requirement already satisfied: bs4 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from fake_headers) (0.0.2)\n",
      "Requirement already satisfied: html5lib in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from fake_headers) (1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.4.2 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (3.1.4)\n",
      "Requirement already satisfied: certifi>=2019.9.11 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (2025.1.31)\n",
      "Requirement already satisfied: hyperframe>=6.0; python_version >= \"3.6.0\" in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (6.0.1)\n",
      "Requirement already satisfied: kaitaistruct>=0.7 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (0.10)\n",
      "Requirement already satisfied: blinker>=1.4 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (1.6.3)\n",
      "Requirement already satisfied: pyasn1>=0.3.1 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (0.5.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (1.2.0)\n",
      "Requirement already satisfied: pyOpenSSL>=22.0.0 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (25.0.0)\n",
      "Requirement already satisfied: zstandard>=0.14.1 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (0.21.0)\n",
      "Requirement already satisfied: h2>=4.0; python_version >= \"3.6.0\" in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (4.1.0)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (1.1.0)\n",
      "Requirement already satisfied: pysocks>=1.7.1 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (1.7.1)\n",
      "Requirement already satisfied: selenium>=4.0.0 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium-wire) (4.11.2)\n",
      "Requirement already satisfied: requests in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: packaging in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from webdriver_manager) (24.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from bs4->fake_headers) (4.13.3)\n",
      "Requirement already satisfied: six>=1.9 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from html5lib->fake_headers) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from html5lib->fake_headers) (0.5.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from wsproto>=0.14->selenium-wire) (0.14.0)\n",
      "Requirement already satisfied: cryptography<45,>=41.0.5 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from pyOpenSSL>=22.0.0->selenium-wire) (44.0.2)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from h2>=4.0; python_version >= \"3.6.0\"->selenium-wire) (4.0.0)\n",
      "Requirement already satisfied: trio~=0.17 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium>=4.0.0->selenium-wire) (0.22.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium>=4.0.0->selenium-wire) (2.0.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from selenium>=4.0.0->selenium-wire) (0.11.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from requests->webdriver_manager) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from requests->webdriver_manager) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from beautifulsoup4->bs4->fake_headers) (4.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from beautifulsoup4->bs4->fake_headers) (2.4.1)\n",
      "Requirement already satisfied: cffi>=1.12; platform_python_implementation != \"PyPy\" in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=22.0.0->selenium-wire) (1.15.1)\n",
      "Requirement already satisfied: sniffio in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from trio~=0.17->selenium>=4.0.0->selenium-wire) (1.3.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from trio~=0.17->selenium>=4.0.0->selenium-wire) (24.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9; python_version < \"3.11\" in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from trio~=0.17->selenium>=4.0.0->selenium-wire) (1.2.2)\n",
      "Requirement already satisfied: outcome in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from trio~=0.17->selenium>=4.0.0->selenium-wire) (1.3.0.post0)\n",
      "Requirement already satisfied: sortedcontainers in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from trio~=0.17->selenium>=4.0.0->selenium-wire) (2.4.0)\n",
      "Requirement already satisfied: pycparser in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from cffi>=1.12; platform_python_implementation != \"PyPy\"->cryptography<45,>=41.0.5->pyOpenSSL>=22.0.0->selenium-wire) (2.21)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from attrs>=20.1.0->trio~=0.17->selenium>=4.0.0->selenium-wire) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->attrs>=20.1.0->trio~=0.17->selenium>=4.0.0->selenium-wire) (3.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/sami/.pyenv/versions/3.7.8/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fake_headers pandas python-dotenv selenium-wire webdriver_manager dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade blinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from fake_headers import Headers\n",
    "from time import sleep\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,\n",
    "    StaleElementReferenceException,\n",
    "    WebDriverException,\n",
    ")\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_key = os.getenv(\"MY_SECRET_KEY\")\n",
    "database_url = os.getenv(\"DATABASE_URL\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Class\n",
    "\n",
    "Class for the progress of the scraper instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Progress:\n",
    "    def __init__(self, current, total) -> None:\n",
    "        self.current = current\n",
    "        self.total = total\n",
    "        pass\n",
    "\n",
    "    def print_progress(self, current) -> None:\n",
    "        self.current = current\n",
    "        progress = current / self.total\n",
    "        bar_length = 40\n",
    "        progress_bar = (\n",
    "            \"[\"\n",
    "            + \"=\" * int(bar_length * progress)\n",
    "            + \"-\" * (bar_length - int(bar_length * progress))\n",
    "            + \"]\"\n",
    "        )\n",
    "        sys.stdout.write(\n",
    "            \"\\rProgress: [{:<40}] {:.2%} {} of {}\".format(\n",
    "                progress_bar, progress, current, self.total\n",
    "            )\n",
    "        )\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scroller Class\n",
    "\n",
    "Class for the scrollbar of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scroller:\n",
    "    def __init__(self, driver) -> None:\n",
    "        self.driver = driver\n",
    "        self.current_position = 0\n",
    "        self.last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "        self.scrolling = True\n",
    "        self.scroll_count = 0\n",
    "        pass\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.current_position = 0\n",
    "        self.last_position = self.driver.execute_script(\"return window.pageYOffset;\")\n",
    "        self.scroll_count = 0\n",
    "        pass\n",
    "\n",
    "    def scroll_to_top(self) -> None:\n",
    "        self.driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        pass\n",
    "\n",
    "    def scroll_to_bottom(self) -> None:\n",
    "        self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        pass\n",
    "\n",
    "    def update_scroll_position(self) -> None:\n",
    "        self.current_position = self.driver.execute_script(\"return window.pageYOffset;\")\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Class\n",
    "\n",
    "Object for the tweet. Including its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        card: WebDriver,\n",
    "        driver: WebDriver,\n",
    "        actions: ActionChains,\n",
    "        scrape_poster_details=False\n",
    "    ) -> None:\n",
    "        self.card = card\n",
    "        self.error = False\n",
    "        self.tweet = None\n",
    "\n",
    "        try:\n",
    "            self.user = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"User-Name\"]//span'\n",
    "            ).text\n",
    "        except NoSuchElementException:\n",
    "            self.error = True\n",
    "            self.user = \"skip\"\n",
    "\n",
    "        try:\n",
    "            self.handle = card.find_element(\n",
    "                \"xpath\", './/span[contains(text(), \"@\")]'\n",
    "            ).text\n",
    "        except NoSuchElementException:\n",
    "            self.error = True\n",
    "            self.handle = \"skip\"\n",
    "\n",
    "        try:\n",
    "            self.date_time = card.find_element(\"xpath\", \".//time\").get_attribute(\n",
    "                \"datetime\"\n",
    "            )\n",
    "\n",
    "            if self.date_time is not None:\n",
    "                self.is_ad = False\n",
    "        except NoSuchElementException:\n",
    "            self.is_ad = True\n",
    "            self.error = True\n",
    "            self.date_time = \"skip\"\n",
    "        \n",
    "        if self.error:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            card.find_element(\n",
    "                \"xpath\", './/*[local-name()=\"svg\" and @data-testid=\"icon-verified\"]'\n",
    "            )\n",
    "\n",
    "            self.verified = True\n",
    "        except NoSuchElementException:\n",
    "            self.verified = False\n",
    "\n",
    "        self.content = \"\"\n",
    "        contents = card.find_elements(\n",
    "            \"xpath\",\n",
    "            '(.//div[@data-testid=\"tweetText\"])[1]/span | (.//div[@data-testid=\"tweetText\"])[1]/a',\n",
    "        )\n",
    "\n",
    "        for index, content in enumerate(contents):\n",
    "            self.content += content.text\n",
    "\n",
    "        try:\n",
    "            self.reply_cnt = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"reply\"]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.reply_cnt == \"\":\n",
    "                self.reply_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.reply_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.retweet_cnt = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"retweet\"]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.retweet_cnt == \"\":\n",
    "                self.retweet_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.retweet_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.like_cnt = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"like\"]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.like_cnt == \"\":\n",
    "                self.like_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.like_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.analytics_cnt = card.find_element(\n",
    "                \"xpath\", './/a[contains(@href, \"/analytics\")]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.analytics_cnt == \"\":\n",
    "                self.analytics_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.analytics_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.tags = card.find_elements(\n",
    "                \"xpath\",\n",
    "                './/a[contains(@href, \"src=hashtag_click\")]',\n",
    "            )\n",
    "\n",
    "            self.tags = [tag.text for tag in self.tags]\n",
    "        except NoSuchElementException:\n",
    "            self.tags = []\n",
    "        \n",
    "        try:\n",
    "            self.mentions = card.find_elements(\n",
    "                \"xpath\",\n",
    "                '(.//div[@data-testid=\"tweetText\"])[1]//a[contains(text(), \"@\")]',\n",
    "            )\n",
    "\n",
    "            self.mentions = [mention.text for mention in self.mentions]\n",
    "        except NoSuchElementException:\n",
    "            self.mentions = []\n",
    "        \n",
    "        try:\n",
    "            raw_emojis = card.find_elements(\n",
    "                \"xpath\",\n",
    "                '(.//div[@data-testid=\"tweetText\"])[1]/img[contains(@src, \"emoji\")]',\n",
    "            )\n",
    "            \n",
    "            self.emojis = [emoji.get_attribute(\"alt\").encode(\"unicode-escape\").decode(\"ASCII\") for emoji in raw_emojis]\n",
    "        except NoSuchElementException:\n",
    "            self.emojis = []\n",
    "        \n",
    "        try:\n",
    "            self.profile_img = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"Tweet-User-Avatar\"]//img'\n",
    "            ).get_attribute(\"src\")\n",
    "        except NoSuchElementException:\n",
    "            self.profile_img = \"\"\n",
    "            \n",
    "        try:\n",
    "            self.tweet_link = self.card.find_element(\n",
    "                \"xpath\",\n",
    "                \".//a[contains(@href, '/status/')]\",\n",
    "            ).get_attribute(\"href\")\n",
    "            self.tweet_id = str(self.tweet_link.split(\"/\")[-1])\n",
    "        except NoSuchElementException:\n",
    "            self.tweet_link = \"\"\n",
    "            self.tweet_id = \"\"\n",
    "        \n",
    "        self.following_cnt = \"0\"\n",
    "        self.followers_cnt = \"0\"\n",
    "        self.user_id = None\n",
    "        \n",
    "        if scrape_poster_details:\n",
    "            el_name = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"User-Name\"]//span'\n",
    "            )\n",
    "            \n",
    "            ext_hover_card = False\n",
    "            ext_user_id = False\n",
    "            ext_following = False\n",
    "            ext_followers = False\n",
    "            hover_attempt = 0\n",
    "            \n",
    "            while not ext_hover_card or not ext_user_id or not ext_following or not ext_followers:\n",
    "                try:\n",
    "                    actions.move_to_element(el_name).perform()\n",
    "                    \n",
    "                    hover_card = driver.find_element(\n",
    "                        \"xpath\",\n",
    "                        '//div[@data-testid=\"hoverCardParent\"]'\n",
    "                    )\n",
    "                    \n",
    "                    ext_hover_card = True\n",
    "                    \n",
    "                    while not ext_user_id:\n",
    "                        try:\n",
    "                            raw_user_id = hover_card.find_element(\n",
    "                                \"xpath\",\n",
    "                                '(.//div[contains(@data-testid, \"-follow\")]) | (.//div[contains(@data-testid, \"-unfollow\")])'\n",
    "                            ).get_attribute(\"data-testid\")\n",
    "                            \n",
    "                            if raw_user_id == \"\":\n",
    "                                self.user_id = None\n",
    "                            else:\n",
    "                                self.user_id = str(raw_user_id.split(\"-\")[0])\n",
    "                            \n",
    "                            ext_user_id = True\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                        except StaleElementReferenceException:\n",
    "                            self.error = True\n",
    "                            return\n",
    "                    \n",
    "                    while not ext_following:\n",
    "                        try:\n",
    "                            self.following_cnt = hover_card.find_element(\n",
    "                                \"xpath\",\n",
    "                                './/a[contains(@href, \"/following\")]//span'\n",
    "                            ).text\n",
    "                            \n",
    "                            if self.following_cnt == \"\":\n",
    "                                self.following_cnt = \"0\"\n",
    "                                \n",
    "                            ext_following = True\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                        except StaleElementReferenceException:\n",
    "                            self.error = True\n",
    "                            return\n",
    "                    \n",
    "                    while not ext_followers:\n",
    "                        try:\n",
    "                            self.followers_cnt = hover_card.find_element(\n",
    "                                \"xpath\",\n",
    "                                './/a[contains(@href, \"/verified_followers\")]//span'\n",
    "                            ).text\n",
    "                            \n",
    "                            if self.followers_cnt == \"\":\n",
    "                                self.followers_cnt = \"0\"\n",
    "                            \n",
    "                            ext_followers = True\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                        except StaleElementReferenceException:\n",
    "                            self.error = True\n",
    "                            return\n",
    "                except NoSuchElementException:\n",
    "                    if hover_attempt==3:\n",
    "                        self.error\n",
    "                        return\n",
    "                    hover_attempt+=1\n",
    "                    sleep(0.5)\n",
    "                    continue\n",
    "                except StaleElementReferenceException:\n",
    "                    self.error = True\n",
    "                    return\n",
    "            \n",
    "            if ext_hover_card and ext_following and ext_followers:\n",
    "                actions.reset_actions()\n",
    "        \n",
    "        self.tweet = (\n",
    "            self.user,\n",
    "            self.handle,\n",
    "            self.date_time,\n",
    "            self.verified,\n",
    "            self.content,\n",
    "            self.reply_cnt,\n",
    "            self.retweet_cnt,\n",
    "            self.like_cnt,\n",
    "            self.analytics_cnt,\n",
    "            self.tags,\n",
    "            self.mentions,\n",
    "            self.emojis,\n",
    "            self.profile_img,\n",
    "            self.tweet_link,\n",
    "            self.tweet_id,\n",
    "            self.user_id,\n",
    "            self.following_cnt,\n",
    "            self.followers_cnt,\n",
    "        )\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraper Class\n",
    "\n",
    "Class for the Twitter Scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "TWITTER_LOGIN_URL = \"https://twitter.com/i/flow/login\"\n",
    "\n",
    "class Twitter_Scraper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        username,\n",
    "        password,\n",
    "        email,\n",
    "        max_tweets=50,\n",
    "        scrape_username=None,\n",
    "        scrape_hashtag=None,\n",
    "        scrape_query=None,\n",
    "        scrape_poster_details=False,\n",
    "        scrape_latest=True,\n",
    "        scrape_top=False,\n",
    "        proxy=None\n",
    "    ):\n",
    "        print(\"Initializing Twitter Scraper...\")\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.email = email\n",
    "        self.proxy = proxy\n",
    "        self.interrupted = False\n",
    "        self.tweet_ids = set()\n",
    "        self.data = []\n",
    "        self.tweet_cards = []\n",
    "        self.scraper_details = {\n",
    "            \"type\": None,\n",
    "            \"username\": None,\n",
    "            \"hashtag\": None,\n",
    "            \"query\": None,\n",
    "            \"tab\": None,\n",
    "            \"poster_details\": False,\n",
    "        }\n",
    "        self.max_tweets = max_tweets\n",
    "        self.progress = Progress(0, max_tweets)\n",
    "        self.router = self.go_to_home\n",
    "        self.driver = self._get_driver()\n",
    "\n",
    "        # ip = self.driver.get(\"http://whatismyipaddress.com\")\n",
    "        # print(\"my IP is : \", ip)\n",
    "        \n",
    "        self.actions = ActionChains(self.driver)\n",
    "        self.scroller = Scroller(self.driver)\n",
    "        self._config_scraper(\n",
    "            max_tweets,\n",
    "            scrape_username,\n",
    "            scrape_hashtag,\n",
    "            scrape_query,\n",
    "            scrape_latest,\n",
    "            scrape_top,\n",
    "            scrape_poster_details,\n",
    "        )\n",
    "        \n",
    "\n",
    "    def _config_scraper(\n",
    "        self,\n",
    "        max_tweets=50,\n",
    "        scrape_username=None,\n",
    "        scrape_hashtag=None,\n",
    "        scrape_query=None,\n",
    "        scrape_latest=True,\n",
    "        scrape_top=False,\n",
    "        scrape_poster_details=False,\n",
    "    ):\n",
    "        self.tweet_ids = set()\n",
    "        self.data = []\n",
    "        self.tweet_cards = []\n",
    "        self.max_tweets = max_tweets\n",
    "        self.progress = Progress(0, max_tweets)\n",
    "        self.scraper_details = {\n",
    "            \"type\": None,\n",
    "            \"username\": scrape_username,\n",
    "            \"hashtag\": str(scrape_hashtag).replace(\"#\", \"\")\n",
    "            if scrape_hashtag is not None\n",
    "            else None,\n",
    "            \"query\": scrape_query,\n",
    "            \"tab\": \"Latest\" if scrape_latest else \"Top\" if scrape_top else \"Latest\",\n",
    "            \"poster_details\": scrape_poster_details,\n",
    "        }\n",
    "        self.router = self.go_to_home\n",
    "        self.scroller = Scroller(self.driver)\n",
    "\n",
    "        if scrape_username is not None:\n",
    "            self.scraper_details[\"type\"] = \"Username\"\n",
    "            self.router = self.go_to_profile\n",
    "        elif scrape_hashtag is not None:\n",
    "            self.scraper_details[\"type\"] = \"Hashtag\"\n",
    "            self.router = self.go_to_hashtag\n",
    "        elif scrape_query is not None:\n",
    "            self.scraper_details[\"type\"] = \"Query\"\n",
    "            self.router = self.go_to_search\n",
    "        else:\n",
    "            self.scraper_details[\"type\"] = \"Home\"\n",
    "            self.router = self.go_to_home\n",
    "        pass\n",
    "\n",
    "    def _get_driver(self):\n",
    "        print(\"Setup WebDriver...\")\n",
    "        header = Headers().generate()[\"User-Agent\"]\n",
    "\n",
    "        browser_option = ChromeOptions()\n",
    "        browser_option.add_argument(\"--no-sandbox\")\n",
    "        browser_option.add_argument(\"--disable-dev-shm-usage\")\n",
    "        browser_option.add_argument(\"--ignore-certificate-errors\")\n",
    "        browser_option.add_argument(\"--disable-gpu\")\n",
    "        browser_option.add_argument(\"--log-level=3\")\n",
    "        browser_option.add_argument(\"--disable-notifications\")\n",
    "        browser_option.add_argument(\"--disable-popup-blocking\")\n",
    "        browser_option.add_argument(\"--user-agent={}\".format(header))\n",
    "\n",
    "        proxies = None\n",
    "        if self.proxy is not None:\n",
    "            # browser_option.add_argument(\"--proxy-server=%s\" % self.proxy)\n",
    "            # browser_option.add_argument('--proxy-server=%s' % PROXY)\n",
    "\n",
    "            proxies = {\n",
    "                'proxy': {\n",
    "                    'http': f'http://{self.proxy}',\n",
    "                    'https': f'https://{self.proxy}',\n",
    "                }\n",
    "            }\n",
    "\n",
    "        # For Hiding Browser\n",
    "        # browser_option.add_argument(\"--headless\")\n",
    "\n",
    "        try:\n",
    "            print(\"Initializing ChromeDriver...\")\n",
    "            driver = webdriver.Chrome(\n",
    "                options=browser_option,\n",
    "                seleniumwire_options=proxies,\n",
    "            )\n",
    "\n",
    "            print(\"WebDriver Setup Complete\")\n",
    "            return driver\n",
    "        except WebDriverException:\n",
    "            try:\n",
    "                print(\"Downloading ChromeDriver...\")\n",
    "                chromedriver_path = ChromeDriverManager().install()\n",
    "                chrome_service = ChromeService(executable_path=chromedriver_path)\n",
    "\n",
    "                print(\"Initializing ChromeDriver...\")\n",
    "                driver = webdriver.Chrome(\n",
    "                    service=chrome_service,\n",
    "                    options=browser_option,\n",
    "                    seleniumwire_options=proxies,\n",
    "                )\n",
    "\n",
    "                print(\"WebDriver Setup Complete\")\n",
    "                return driver\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting up WebDriver: {e}\")\n",
    "                sys.exit(1)\n",
    "        pass\n",
    "\n",
    "    def login(self):\n",
    "        print()\n",
    "        print(\"Logging in to Twitter...\")\n",
    "\n",
    "        try:\n",
    "            self.driver.maximize_window()\n",
    "            self.driver.get(TWITTER_LOGIN_URL)\n",
    "            sleep(3)\n",
    "\n",
    "            self._input_username()\n",
    "            self._input_unusual_activity()\n",
    "            self._input_password()\n",
    "\n",
    "            cookies = self.driver.get_cookies()\n",
    "\n",
    "            auth_token = None\n",
    "\n",
    "            for cookie in cookies:\n",
    "                if cookie[\"name\"] == \"auth_token\":\n",
    "                    auth_token = cookie[\"value\"]\n",
    "                    break\n",
    "\n",
    "            if auth_token is None:\n",
    "                raise ValueError(\n",
    "                    \"\"\"This may be due to the following:\n",
    "\n",
    "- Internet connection is unstable\n",
    "- Username is incorrect\n",
    "- Password is incorrect\n",
    "\"\"\"\n",
    "                )\n",
    "\n",
    "            print()\n",
    "            print(\"Login Successful\")\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(f\"Login Failed: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _input_username(self):\n",
    "        input_attempt = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                username = WebDriverWait(self.driver, 30).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//input[@autocomplete='username']\"))\n",
    "                )\n",
    "\n",
    "                username.send_keys(self.email)\n",
    "                username.send_keys(Keys.RETURN)\n",
    "                sleep(3)\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                input_attempt += 1\n",
    "                if input_attempt >= 3:\n",
    "                    print()\n",
    "                    print(\n",
    "                        \"\"\"There was an error inputting the username.\n",
    "\n",
    "It may be due to the following:\n",
    "- Internet connection is unstable\n",
    "- Username is incorrect\n",
    "- Twitter is experiencing unusual activity\"\"\"\n",
    "                    )\n",
    "                    self.driver.quit()\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    print(\"Re-attempting to input username...\")\n",
    "                    sleep(2)\n",
    "\n",
    "    def _input_unusual_activity(self):\n",
    "        input_attempt = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                \n",
    "                unusual_activity = WebDriverWait(self.driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//input[@data-testid='ocfEnterTextTextInput']\"))\n",
    "                )\n",
    "                unusual_activity.send_keys(self.username)\n",
    "                unusual_activity.send_keys(Keys.RETURN)\n",
    "                sleep(3)\n",
    "                break\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                input_attempt += 1\n",
    "                if input_attempt >= 3:\n",
    "                    break\n",
    "\n",
    "    def _input_password(self):\n",
    "        input_attempt = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                password = WebDriverWait(self.driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//input[@autocomplete='current-password']\"))\n",
    "                )\n",
    "\n",
    "                password.send_keys(self.password)\n",
    "                password.send_keys(Keys.RETURN)\n",
    "                sleep(3)\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                input_attempt += 1\n",
    "                if input_attempt >= 3:\n",
    "                    print()\n",
    "                    print(\n",
    "                        \"\"\"There was an error inputting the password.\n",
    "\n",
    "It may be due to the following:\n",
    "- Internet connection is unstable\n",
    "- Password is incorrect\n",
    "- Twitter is experiencing unusual activity\"\"\"\n",
    "                    )\n",
    "                    self.driver.quit()\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    print(\"Re-attempting to input password...\")\n",
    "                    sleep(2)\n",
    "\n",
    "    def go_to_home(self):\n",
    "        self.driver.get(\"https://twitter.com/home\")\n",
    "        sleep(3)\n",
    "        pass\n",
    "\n",
    "    def go_to_profile(self):\n",
    "        if (\n",
    "            self.scraper_details[\"username\"] is None\n",
    "            or self.scraper_details[\"username\"] == \"\"\n",
    "        ):\n",
    "            print(\"Username is not set.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            self.driver.get(f\"https://twitter.com/{self.scraper_details['username']}\")\n",
    "            sleep(3)\n",
    "        pass\n",
    "\n",
    "    def go_to_hashtag(self):\n",
    "        if (\n",
    "            self.scraper_details[\"hashtag\"] is None\n",
    "            or self.scraper_details[\"hashtag\"] == \"\"\n",
    "        ):\n",
    "            print(\"Hashtag is not set.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            url = f\"https://twitter.com/hashtag/{self.scraper_details['hashtag']}?src=hashtag_click\"\n",
    "            if self.scraper_details[\"tab\"] == \"Latest\":\n",
    "                url += \"&f=live\"\n",
    "\n",
    "            self.driver.get(url)\n",
    "            sleep(3)\n",
    "        pass\n",
    "\n",
    "    def go_to_search(self):\n",
    "        if self.scraper_details[\"query\"] is None or self.scraper_details[\"query\"] == \"\":\n",
    "            print(\"Query is not set.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            url = f\"https://twitter.com/search?q={self.scraper_details['query']}&src=typed_query\"\n",
    "            if self.scraper_details[\"tab\"] == \"Latest\":\n",
    "                url += \"&f=live\"\n",
    "\n",
    "            self.driver.get(url)\n",
    "            sleep(3)\n",
    "        pass\n",
    "\n",
    "    def get_tweet_cards(self):\n",
    "        self.tweet_cards = self.driver.find_elements(\n",
    "            \"xpath\", '//article[@data-testid=\"tweet\" and not(@disabled)]'\n",
    "        )\n",
    "        pass\n",
    "\n",
    "    def remove_hidden_cards(self):\n",
    "        try:\n",
    "            hidden_cards = self.driver.find_elements(\n",
    "                \"xpath\", '//article[@data-testid=\"tweet\" and @disabled]'\n",
    "            )\n",
    "\n",
    "            for card in hidden_cards[1:-2]:\n",
    "                self.driver.execute_script(\n",
    "                    \"arguments[0].parentNode.parentNode.parentNode.remove();\", card\n",
    "                )\n",
    "        except Exception as e:\n",
    "            return\n",
    "        pass\n",
    "\n",
    "    def scrape_tweets(\n",
    "        self,\n",
    "        max_tweets=50,\n",
    "        scrape_username=None,\n",
    "        scrape_hashtag=None,\n",
    "        scrape_query=None,\n",
    "        scrape_latest=True,\n",
    "        scrape_top=False,\n",
    "        scrape_poster_details=False,\n",
    "        router=None,\n",
    "    ):\n",
    "        self._config_scraper(\n",
    "            max_tweets,\n",
    "            scrape_username,\n",
    "            scrape_hashtag,\n",
    "            scrape_query,\n",
    "            scrape_latest,\n",
    "            scrape_top,\n",
    "            scrape_poster_details,\n",
    "        )\n",
    "\n",
    "        if router is None:\n",
    "            router = self.router\n",
    "\n",
    "        router()\n",
    "\n",
    "        if self.scraper_details[\"type\"] == \"Username\":\n",
    "            print(\n",
    "                \"Scraping Tweets from @{}...\".format(self.scraper_details[\"username\"])\n",
    "            )\n",
    "        elif self.scraper_details[\"type\"] == \"Hashtag\":\n",
    "            print(\n",
    "                \"Scraping {} Tweets from #{}...\".format(\n",
    "                    self.scraper_details[\"tab\"], self.scraper_details[\"hashtag\"]\n",
    "                )\n",
    "            )\n",
    "        elif self.scraper_details[\"type\"] == \"Query\":\n",
    "            print(\n",
    "                \"Scraping {} Tweets from {} search...\".format(\n",
    "                    self.scraper_details[\"tab\"], self.scraper_details[\"query\"]\n",
    "                )\n",
    "            )\n",
    "        elif self.scraper_details[\"type\"] == \"Home\":\n",
    "            print(\"Scraping Tweets from Home...\")\n",
    "\n",
    "        self.progress.print_progress(0)\n",
    "\n",
    "        refresh_count = 0\n",
    "        added_tweets = 0\n",
    "        empty_count = 0\n",
    "\n",
    "        while self.scroller.scrolling:\n",
    "            try:\n",
    "                self.get_tweet_cards()\n",
    "                added_tweets = 0\n",
    "\n",
    "                for card in self.tweet_cards[-15:]:\n",
    "                    try:\n",
    "                        tweet_id = str(card)\n",
    "\n",
    "                        if tweet_id not in self.tweet_ids:\n",
    "                            self.tweet_ids.add(tweet_id)\n",
    "\n",
    "                            if not self.scraper_details[\"poster_details\"]:\n",
    "                                self.driver.execute_script(\n",
    "                                    \"arguments[0].scrollIntoView();\", card\n",
    "                                )\n",
    "\n",
    "                            tweet = Tweet(\n",
    "                                card=card,\n",
    "                                driver=self.driver,\n",
    "                                actions=self.actions,\n",
    "                                scrape_poster_details=self.scraper_details[\n",
    "                                    \"poster_details\"\n",
    "                                ],\n",
    "                            )\n",
    "\n",
    "                            if tweet:\n",
    "                                if not tweet.error and tweet.tweet is not None:\n",
    "                                    if not tweet.is_ad:\n",
    "                                        self.data.append(tweet.tweet)\n",
    "                                        added_tweets += 1\n",
    "                                        self.progress.print_progress(len(self.data))\n",
    "\n",
    "                                        if len(self.data) >= self.max_tweets:\n",
    "                                            self.scroller.scrolling = False\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        continue\n",
    "                                else:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "                    except NoSuchElementException:\n",
    "                        continue\n",
    "\n",
    "                if len(self.data) >= self.max_tweets:\n",
    "                    break\n",
    "\n",
    "                if added_tweets == 0:\n",
    "                    if empty_count >= 5:\n",
    "                        if refresh_count >= 3:\n",
    "                            print()\n",
    "                            print(\"No more tweets to scrape\")\n",
    "                            break\n",
    "                        refresh_count += 1\n",
    "                    empty_count += 1\n",
    "                    sleep(1)\n",
    "                else:\n",
    "                    empty_count = 0\n",
    "                    refresh_count = 0\n",
    "            except StaleElementReferenceException:\n",
    "                sleep(2)\n",
    "                continue\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\")\n",
    "                print(\"Keyboard Interrupt\")\n",
    "                self.interrupted = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"\\n\")\n",
    "                print(f\"Error scraping tweets: {e}\")\n",
    "                break\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        if len(self.data) >= self.max_tweets:\n",
    "            print(\"Scraping Complete\")\n",
    "        else:\n",
    "            print(\"Scraping Incomplete\")\n",
    "\n",
    "        print(\"Tweets: {} out of {}\\n\".format(len(self.data), self.max_tweets))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def save_to_csv(self, file_name=None):\n",
    "        print(\"Saving Tweets to CSV...\")\n",
    "        now = datetime.now()\n",
    "        folder_path = \"./tweets/\"\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            print(\"Created Folder: {}\".format(folder_path))\n",
    "\n",
    "        data = {\n",
    "            \"Name\": [tweet[0] for tweet in self.data],\n",
    "            \"Handle\": [tweet[1] for tweet in self.data],\n",
    "            # \"Timestamp\": [tweet[2] for tweet in self.data],\n",
    "            \"Verified\": [tweet[3] for tweet in self.data],\n",
    "            \"Content\": [tweet[4] for tweet in self.data],\n",
    "            # \"Comments\": [tweet[5] for tweet in self.data],\n",
    "            # \"Retweets\": [tweet[6] for tweet in self.data],\n",
    "            \"Likes\": [tweet[7] for tweet in self.data],\n",
    "            # \"Analytics\": [tweet[8] for tweet in self.data],\n",
    "            \"Tags\": [tweet[9] for tweet in self.data],\n",
    "            # \"Mentions\": [tweet[10] for tweet in self.data],\n",
    "            # \"Emojis\": [tweet[11] for tweet in self.data],\n",
    "            # \"Profile Image\": [tweet[12] for tweet in self.data],\n",
    "            \"Tweet Link\": [tweet[13] for tweet in self.data],\n",
    "            \"Tweet ID\": [f'tweet_id:{tweet[14]}' for tweet in self.data],\n",
    "        }\n",
    "\n",
    "        if self.scraper_details[\"poster_details\"]:\n",
    "            data[\"Tweeter ID\"] = [f'user_id:{tweet[15]}' for tweet in self.data]\n",
    "            data[\"Following\"] = [tweet[16] for tweet in self.data]\n",
    "            data[\"Followers\"] = [tweet[17] for tweet in self.data]\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        file_path = f\"{folder_path}{file_name if file_name is not None else ''}_{current_time}_tweets_1-{len(self.data)}.csv\"\n",
    "        pd.set_option(\"display.max_colwidth\", None)\n",
    "        df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "        print(\"CSV Saved: {}\".format(file_path))\n",
    "\n",
    "    def get_json(self):\n",
    "        \n",
    "        json_data = []\n",
    "\n",
    "        for tweet in self.data:\n",
    "            tweet_data = {\n",
    "                \"Name\": tweet[0],\n",
    "                \"Handle\": tweet[1],\n",
    "                \"Timestamp\": tweet[2],\n",
    "                \"Verified\": tweet[3],\n",
    "                \"Content\": tweet[4],\n",
    "                \"Comments\": tweet[5],\n",
    "                \"Retweets\": tweet[6],\n",
    "                \"Likes\": tweet[7],\n",
    "                \"Analytics\": tweet[8],\n",
    "                \"Tags\": tweet[9],\n",
    "                \"Mentions\": tweet[10],\n",
    "                \"Emojis\": tweet[11],\n",
    "                \"Profile Image\": tweet[12],\n",
    "                \"Tweet Link\": tweet[13],\n",
    "                \"Tweet ID\": f'tweet_id:{tweet[14]}',\n",
    "            }\n",
    "\n",
    "            if self.scraper_details[\"poster_details\"]:\n",
    "                tweet_data[\"Tweeter ID\"] = f'user_id:{tweet[15]}'\n",
    "                tweet_data[\"Following\"] = tweet[16]\n",
    "                tweet_data[\"Followers\"] = tweet[17]\n",
    "\n",
    "            json_data.append(tweet_data)\n",
    "\n",
    "        return json_data\n",
    "\n",
    "    def get_tweets(self):\n",
    "        return self.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new instance of the Twitter Scraper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to login as samibre121...\n",
      "Initializing Twitter Scraper...\n",
      "Setup WebDriver...\n",
      "Initializing ChromeDriver...\n",
      "WebDriver Setup Complete\n",
      "\n",
      "Logging in to Twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Login Failed: Message: \n",
      "Stacktrace:\n",
      "#0 0x562db73d846a <unknown>\n",
      "#1 0x562db6e91ed0 <unknown>\n",
      "#2 0x562db6ee3935 <unknown>\n",
      "#3 0x562db6ee3b61 <unknown>\n",
      "#4 0x562db6f329d4 <unknown>\n",
      "#5 0x562db6f0988d <unknown>\n",
      "#6 0x562db6f2fceb <unknown>\n",
      "#7 0x562db6f09633 <unknown>\n",
      "#8 0x562db6ed51be <unknown>\n",
      "#9 0x562db6ed6981 <unknown>\n",
      "#10 0x562db739e86b <unknown>\n",
      "#11 0x562db73a273c <unknown>\n",
      "#12 0x562db7385f12 <unknown>\n",
      "#13 0x562db73a32b4 <unknown>\n",
      "#14 0x562db736a0af <unknown>\n",
      "#15 0x562db73c6ad8 <unknown>\n",
      "#16 0x562db73c6cb6 <unknown>\n",
      "#17 0x562db73d72e6 <unknown>\n",
      "#18 0x7f46031a2aa4 <unknown>\n",
      "#19 0x7f460322fc3c <unknown>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3352/346473127.py\", line 167, in login\n",
      "    self._input_username()\n",
      "  File \"/tmp/ipykernel_3352/346473127.py\", line 206, in _input_username\n",
      "    EC.presence_of_element_located((By.XPATH, \"//input[@autocomplete='username']\"))\n",
      "  File \"/home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages/selenium/webdriver/support/wait.py\", line 95, in until\n",
      "    raise TimeoutException(message, screen, stacktrace)\n",
      "selenium.common.exceptions.TimeoutException: Message: \n",
      "Stacktrace:\n",
      "#0 0x562db73d846a <unknown>\n",
      "#1 0x562db6e91ed0 <unknown>\n",
      "#2 0x562db6ee3935 <unknown>\n",
      "#3 0x562db6ee3b61 <unknown>\n",
      "#4 0x562db6f329d4 <unknown>\n",
      "#5 0x562db6f0988d <unknown>\n",
      "#6 0x562db6f2fceb <unknown>\n",
      "#7 0x562db6f09633 <unknown>\n",
      "#8 0x562db6ed51be <unknown>\n",
      "#9 0x562db6ed6981 <unknown>\n",
      "#10 0x562db739e86b <unknown>\n",
      "#11 0x562db73a273c <unknown>\n",
      "#12 0x562db7385f12 <unknown>\n",
      "#13 0x562db73a32b4 <unknown>\n",
      "#14 0x562db736a0af <unknown>\n",
      "#15 0x562db73c6ad8 <unknown>\n",
      "#16 0x562db73c6cb6 <unknown>\n",
      "#17 0x562db73d72e6 <unknown>\n",
      "#18 0x7f46031a2aa4 <unknown>\n",
      "#19 0x7f460322fc3c <unknown>\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3352/2252212635.py\", line 73, in <module>\n",
      "    scraper.login()\n",
      "  File \"/tmp/ipykernel_3352/346473127.py\", line 196, in login\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/sami/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/sami/.pyenv/versions/3.7.8/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3352/346473127.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_username\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_unusual_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3352/346473127.py\u001b[0m in \u001b[0;36m_input_username\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 username = WebDriverWait(self.driver, 30).until(\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"//input[@autocomplete='username']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                 )\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n#0 0x562db73d846a <unknown>\n#1 0x562db6e91ed0 <unknown>\n#2 0x562db6ee3935 <unknown>\n#3 0x562db6ee3b61 <unknown>\n#4 0x562db6f329d4 <unknown>\n#5 0x562db6f0988d <unknown>\n#6 0x562db6f2fceb <unknown>\n#7 0x562db6f09633 <unknown>\n#8 0x562db6ed51be <unknown>\n#9 0x562db6ed6981 <unknown>\n#10 0x562db739e86b <unknown>\n#11 0x562db73a273c <unknown>\n#12 0x562db7385f12 <unknown>\n#13 0x562db73a32b4 <unknown>\n#14 0x562db736a0af <unknown>\n#15 0x562db73c6ad8 <unknown>\n#16 0x562db73c6cb6 <unknown>\n#17 0x562db73d72e6 <unknown>\n#18 0x7f46031a2aa4 <unknown>\n#19 0x7f460322fc3c <unknown>\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3352/2252212635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         )\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3352/346473127.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Login Failed: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2092\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2093\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    632\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "proxy_username = os.getenv(\"OXYLABS_USERNAME\")\n",
    "proxy_password = os.getenv(\"OXYLABS_PASSWORD\")\n",
    "\n",
    "\n",
    "twitter_accounts = [\n",
    "    {\n",
    "        \"username\": \"BobXonax96169\",\n",
    "        \"password\": \"pacofthemonth12\",\n",
    "        \"email\": \"xonax96169@egvoo.com\",\n",
    "    },\n",
    "    {\n",
    "        \"username\": \"goniyah461\",\n",
    "        \"password\": \"busyCorner0\",\n",
    "        \"email\": \"goniyah461@jomspar.com\",\n",
    "    },  \n",
    "    {\n",
    "        \"username\": \"lemakag\",\n",
    "        \"password\": \"simminassor444\",\n",
    "        \"email\": \"lemakag320@hartaria.com\",\n",
    "    },\n",
    "    {\n",
    "        \"username\": \"fopepe1943\",\n",
    "        \"password\": \"mistymistress\",\n",
    "        \"email\": \"fopepe1129@egvoo.com\",\n",
    "    },\n",
    "    {\n",
    "        \"username\": \"utanim282233\",\n",
    "        \"password\": \"otpwas858040\",\n",
    "        \"email\": \"davoyop211@egvoo.com\",\n",
    "    },\n",
    "    {\n",
    "        \"username\": \"pehijib\",\n",
    "        \"password\": \"Godiswithus\",\n",
    "        \"email\": \"pehijib856@lassora.com\",\n",
    "    },\n",
    "    {\n",
    "        \"username\": \"xedapo8494\",\n",
    "        \"password\": \"mimininjas\",\n",
    "        \"email\": \"xedapo8494@jomspar.com\",\n",
    "    },\n",
    "    {\n",
    "        \"username\": \"billie381480791\",\n",
    "        \"password\": \"simminglybeyond\",\n",
    "        \"email\": \"xirama9341@egvoo.com\",\n",
    "    }\n",
    "]\n",
    "\n",
    "random.shuffle(twitter_accounts)\n",
    "\n",
    "for account in twitter_accounts:\n",
    "    try:\n",
    "        print(f\"Attempting to login as {account['username']}...\")\n",
    "        scraper = Twitter_Scraper(\n",
    "            username=account[\"username\"],\n",
    "            password=account[\"password\"],\n",
    "            email=account[\"email\"],\n",
    "            max_tweets=10,\n",
    "            scrape_username=\"dankeris\",\n",
    "            scrape_latest=False,\n",
    "            proxy=f'{proxy_username}:{proxy_password}@pr.oxylabs.io:7777'\n",
    "        )\n",
    "        scraper.login()\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Login failed for {account['username']}: {e}\")\n",
    "else:\n",
    "    print(\"All login attempts failed\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Twitter Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Tweets from @fireship_dev...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scraper.scrape_tweets(\n",
    "    max_tweets=50,\n",
    "    scrape_username=\"fireship_dev\",\n",
    "    # scrape_hashtag=\"something\",\n",
    "    # scrape_query=\"something\",\n",
    "    scrape_latest=False,\n",
    "    # scrape_top=True,\n",
    "    # scrape_poster_details=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print data in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tweets_json = scraper.get_json()\n",
    "print(json.dumps(tweets_json, indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Scraped Tweets in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/_2025-03-10_12-09-26_tweets_1-0.csv\n"
     ]
    }
   ],
   "source": [
    "scraper.save_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Tweets from @dankeris...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/dankeris_2025-03-10_12-09-39_tweets_1-0.csv\n",
      "Scraping Tweets from @kalibetre...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/kalibetre_2025-03-10_12-09-56_tweets_1-0.csv\n",
      "Scraping Tweets from @Linus__Torvalds...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/Linus__Torvalds_2025-03-10_12-10-13_tweets_1-0.csv\n",
      "Scraping Tweets from @fireship_dev...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/fireship_dev_2025-03-10_12-10-30_tweets_1-0.csv\n",
      "Scraping Tweets from @GergelyOrosz...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/GergelyOrosz_2025-03-10_12-10-47_tweets_1-0.csv\n",
      "Scraping Tweets from @JoshuaFluke...\n",
      "Progress: [[----------------------------------------]] 0.00% 0 of 50\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 0 out of 50\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: ./tweets/JoshuaFluke_2025-03-10_12-11-04_tweets_1-0.csv\n"
     ]
    }
   ],
   "source": [
    "scrape_usernames = [\n",
    "    \"dankeris\",\n",
    "    \"kalibetre\",\n",
    "    \"Linus__Torvalds\",\n",
    "    \"fireship_dev\",\n",
    "    \"GergelyOrosz\",\n",
    "    \"JoshuaFluke\",\n",
    "]\n",
    "\n",
    "for scrape_username in scrape_usernames:\n",
    "    \n",
    "\n",
    "    scraper.scrape_tweets(\n",
    "        max_tweets=50,\n",
    "        scrape_username=scrape_username,\n",
    "        scrape_latest=True,\n",
    "    )\n",
    "\n",
    "    scraper.save_to_csv(file_name=scrape_username)\n",
    "    sleep(5)\n",
    "\n",
    "    \n",
    "scraper.driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally we close the scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id\nStacktrace:\n#0 0x55f7ca6bb46a <unknown>\n#1 0x55f7ca174d23 <unknown>\n#2 0x55f7ca1b7adf <unknown>\n#3 0x55f7ca1ec766 <unknown>\n#4 0x55f7ca1e6dd3 <unknown>\n#5 0x55f7ca1e60a5 <unknown>\n#6 0x55f7ca13daf8 <unknown>\n#7 0x55f7ca68186b <unknown>\n#8 0x55f7ca68573c <unknown>\n#9 0x55f7ca668f12 <unknown>\n#10 0x55f7ca6862b4 <unknown>\n#11 0x55f7ca64d0af <unknown>\n#12 0x55f7ca13c52b <unknown>\n#13 0x7f87ca6aa1ca <unknown>\n#14 0x7f87ca6aa28b __libc_start_main\n#15 0x55f7ca1053ea _start\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:579\u001b[0m, in \u001b[0;36mWebDriver.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Closes the current window.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    >>> driver.close()\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLOSE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mInvalidSessionIdException\u001b[0m: Message: invalid session id\nStacktrace:\n#0 0x55f7ca6bb46a <unknown>\n#1 0x55f7ca174d23 <unknown>\n#2 0x55f7ca1b7adf <unknown>\n#3 0x55f7ca1ec766 <unknown>\n#4 0x55f7ca1e6dd3 <unknown>\n#5 0x55f7ca1e60a5 <unknown>\n#6 0x55f7ca13daf8 <unknown>\n#7 0x55f7ca68186b <unknown>\n#8 0x55f7ca68573c <unknown>\n#9 0x55f7ca668f12 <unknown>\n#10 0x55f7ca6862b4 <unknown>\n#11 0x55f7ca64d0af <unknown>\n#12 0x55f7ca13c52b <unknown>\n#13 0x7f87ca6aa1ca <unknown>\n#14 0x7f87ca6aa28b __libc_start_main\n#15 0x55f7ca1053ea _start\n"
     ]
    }
   ],
   "source": [
    "scraper.driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.7.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
